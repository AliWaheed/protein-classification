{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_dpc.csv')\n",
    "\n",
    "label = df['positive|P02647|APO']\n",
    "\n",
    "df = df.drop(['positive|P02647|APO'], axis = 1)\n",
    "\n",
    "label = list(label)\n",
    "count = 0\n",
    "for i in label:\n",
    "    \n",
    "    if 'negative' in i:\n",
    "        label[count] = '0'\n",
    "    else:\n",
    "        label[count] = '1'\n",
    "    \n",
    "    count+=1\n",
    "    \n",
    "headers = list()\n",
    "for i in range(400):\n",
    "    headers.append(i+1)\n",
    "    \n",
    "df.columns = headers\n",
    "df['Labels'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Labels']\n",
    "df.drop(['Labels'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(10)\n",
    "\n",
    "pca = decomposition.PCA(n_components = 2)\n",
    "pca.fit(df)\n",
    "df = pca.transform(df)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 50, oob_score = True, n_jobs = -1, warm_start = True).fit(df, target.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:841: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-9.09644831e-03  1.38231078e-02 -7.31619587e-03  9.95413121e-03\n -1.90012921e-02 -1.13804089e-02 -1.09929591e-02  1.05879921e-03\n -2.64849886e-03  4.40787002e-02 -1.97146665e-02 -2.03317367e-02\n -1.39569696e-02 -1.51614696e-02  1.37908338e-03  3.04931663e-02\n  5.06368838e-03  4.41908687e-02 -2.27420088e-02 -2.72258241e-02\n -7.53324945e-03  2.15330394e-03 -1.07269818e-02 -2.09965929e-03\n -8.80519487e-03  2.50252280e-02 -1.33980513e-02 -7.54877785e-03\n -1.80427153e-02 -1.04813054e-02 -1.07018640e-02  1.05605731e-02\n -1.29633294e-02 -2.33820593e-03 -1.13089243e-02  5.96483937e-03\n -4.23550187e-03  3.87163572e-02 -4.97178407e-03  9.69201699e-03\n -1.58207938e-02 -1.36674270e-02 -1.22219417e-02  1.32748038e-02\n -2.47044768e-03  1.61563717e-02 -6.44238060e-03  6.82788482e-03\n -1.35086151e-02 -1.53388095e-03 -1.13673732e-02 -9.64246783e-03\n -1.47731258e-02 -8.88269115e-03 -2.40764744e-03 -1.47740599e-02\n -9.57605988e-03  1.59196332e-02 -1.11312224e-02  1.46966632e-02\n -9.95430630e-03  1.71139892e-02 -2.74963747e-03  5.00850342e-02\n -4.21935780e-04  4.50983793e-02 -7.87406415e-03 -1.07329916e-02\n -1.32510848e-02 -1.54813975e-02  2.74343248e-02 -2.01084814e-03\n  1.04009658e-02  8.74902215e-03 -1.79225840e-02 -1.51767032e-02\n -7.99472164e-03  2.70181056e-02 -1.85326755e-03  2.31472645e-02\n -5.87810762e-03 -1.82054825e-02 -1.47399632e-02 -9.31331795e-03\n -6.47707982e-03 -1.02094859e-02 -1.99238677e-03 -6.79577235e-03\n -4.55139903e-03 -5.16729755e-03  1.32089965e-02  3.03320773e-03\n  6.02915371e-03  1.67796426e-02  4.79263179e-02  1.18438259e-01\n -3.84312379e-03 -1.79448575e-02  2.34223975e-04 -2.72942279e-02\n -7.65192090e-03 -1.73818190e-02  3.68986418e-03 -1.69613939e-02\n  4.05282248e-03 -2.17468967e-03 -1.22745882e-03  5.60747180e-03\n -5.77778742e-03 -1.92100415e-03 -2.39439290e-02 -9.25192516e-03\n  2.03177538e-02 -1.74451042e-02 -5.74261509e-03 -1.55136390e-02\n -2.29740310e-02 -1.85036194e-02  9.03297309e-03 -9.58338671e-04\n  2.28778040e-03  1.74048990e-02 -3.09807295e-03 -1.41907847e-02\n -1.10980207e-02 -4.28873673e-03 -1.42735858e-02 -1.07261436e-02\n  6.79549109e-03  1.05254324e-02 -8.26286152e-03 -1.16259733e-04\n -5.77471079e-03 -7.01528741e-03 -1.09376721e-02 -2.52304096e-02\n -1.60778146e-02 -3.25628370e-02 -4.39757016e-03 -1.50404517e-02\n  1.41684357e-02  2.10430613e-03 -4.02390352e-03 -8.54851305e-03\n  1.04183098e-02 -2.88566630e-02 -1.16745373e-02 -1.35866497e-02\n -2.73717986e-03 -3.95432720e-03  3.12655629e-03 -9.86162480e-03\n -5.42532746e-03 -1.65288076e-02 -9.16885678e-03 -2.36178958e-03\n  8.44173972e-03 -3.75277773e-02 -5.58282156e-03 -1.20817171e-02\n  1.23644369e-02 -2.02595778e-02  1.22572239e-02 -3.56633635e-03\n  3.21467174e-03  2.07786821e-03 -1.84619939e-03  2.98280548e-03\n -2.88315746e-03 -3.27647035e-03  1.04995735e-03 -1.49867535e-02\n -1.80263582e-04 -1.08881127e-02 -3.63583770e-03 -1.44072575e-02\n  2.35486007e-03  5.44905616e-03  4.30968903e-05 -5.58915967e-03\n  1.58288353e-03  1.12540834e-03  1.50501111e-03  4.85622513e-05\n  7.10887238e-02  2.45623905e-02  4.17112326e-03  9.68663301e-03\n -2.44593015e-03 -1.35366153e-02  2.65697092e-02  5.69682522e-03\n  8.83114524e-03  9.76116024e-03  3.58142029e-03  1.11642666e-02\n -3.62640107e-03 -9.25896317e-03 -2.68877810e-03 -1.65342744e-02\n -4.71546175e-03  5.17536933e-03 -6.08773436e-03  1.57244802e-02\n  1.35418335e-02  6.90288888e-03  2.63715629e-02  3.28032970e-02\n -5.52940764e-04 -2.82129776e-02  6.78708265e-03 -1.93769753e-03\n  2.58140452e-02  2.20634669e-04 -2.67390953e-03  1.35877468e-02\n -9.97097883e-03 -1.07128946e-02 -4.14283155e-03 -1.91842194e-03\n  2.51876175e-01 -5.45801334e-02 -1.16688444e-03 -7.58179929e-03\n -6.43453188e-03  3.76904407e-03 -5.95489750e-03 -1.11942217e-02\n -1.98358507e-03 -3.97853274e-03 -5.48746623e-03 -1.72425155e-02\n  6.91921450e-03  2.08226102e-03  4.07312112e-03  8.47579725e-03\n  4.02667880e-04 -2.88728089e-03  8.56931438e-04  3.78236244e-03\n  1.24191595e-02  1.58070102e-02  9.47103743e-03 -8.79033818e-04\n  2.02814839e-03 -1.47699127e-02  1.40712531e-02  2.17357706e-02\n -1.21472189e-02  6.67436840e-03  1.23163993e-02  1.16995014e-02\n -1.09447464e-02 -1.06686270e-02 -1.07520465e-02 -5.71267866e-03\n -3.97031847e-03  3.01123085e-03 -3.50862253e-03  1.08143138e-02\n  7.09780399e-03  3.86474691e-02 -8.64547770e-03 -1.57216936e-02\n -1.60572585e-03  1.51186169e-03 -2.14366300e-04  2.19937623e-03\n -1.35735171e-02  1.32408794e-02 -6.37209043e-03 -2.62701027e-02\n  2.04956438e-02 -1.11661234e-03 -6.14005560e-03 -5.91984310e-04\n -9.11653414e-03 -1.15093496e-02 -1.81612968e-02 -1.38785075e-02\n  3.56548443e-03  3.16919945e-02 -3.88763775e-03 -1.27605977e-03\n -7.26699363e-03 -1.12618888e-02  4.03732955e-02 -3.11432444e-02\n -8.70184787e-03 -1.92339141e-02 -3.09313228e-03 -6.55319076e-03\n  1.16343843e-02 -2.40492020e-02 -1.62653590e-03  1.55232521e-03\n -2.70218519e-03  3.35494988e-03  1.39744142e-02  1.74429864e-02\n  1.87636018e-02  1.99969552e-04  8.50964244e-03 -6.41091587e-03\n  4.34410805e-03 -1.18281031e-02 -1.46821821e-02 -7.44524598e-03\n  2.59720627e-02  1.88644063e-02  1.45326136e-02  2.93417834e-02\n  2.39911843e-02  2.94267386e-03  7.39233277e-04  4.35112230e-03\n  9.72558837e-03  4.48903674e-03  1.46556029e-03  5.04063303e-03\n -3.42193106e-03 -1.79710146e-02  1.16284229e-02 -4.36905102e-04\n -1.01666730e-02 -4.44995426e-03  2.59177536e-02 -2.31557637e-02\n  1.26353214e-02  2.62941252e-02  1.41547117e-02  2.49826927e-02\n -1.46170743e-02 -2.31623128e-02  5.82614541e-03  1.16367415e-02\n -1.13630202e-03 -2.28386149e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-883702ac8888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-9.09644831e-03  1.38231078e-02 -7.31619587e-03  9.95413121e-03\n -1.90012921e-02 -1.13804089e-02 -1.09929591e-02  1.05879921e-03\n -2.64849886e-03  4.40787002e-02 -1.97146665e-02 -2.03317367e-02\n -1.39569696e-02 -1.51614696e-02  1.37908338e-03  3.04931663e-02\n  5.06368838e-03  4.41908687e-02 -2.27420088e-02 -2.72258241e-02\n -7.53324945e-03  2.15330394e-03 -1.07269818e-02 -2.09965929e-03\n -8.80519487e-03  2.50252280e-02 -1.33980513e-02 -7.54877785e-03\n -1.80427153e-02 -1.04813054e-02 -1.07018640e-02  1.05605731e-02\n -1.29633294e-02 -2.33820593e-03 -1.13089243e-02  5.96483937e-03\n -4.23550187e-03  3.87163572e-02 -4.97178407e-03  9.69201699e-03\n -1.58207938e-02 -1.36674270e-02 -1.22219417e-02  1.32748038e-02\n -2.47044768e-03  1.61563717e-02 -6.44238060e-03  6.82788482e-03\n -1.35086151e-02 -1.53388095e-03 -1.13673732e-02 -9.64246783e-03\n -1.47731258e-02 -8.88269115e-03 -2.40764744e-03 -1.47740599e-02\n -9.57605988e-03  1.59196332e-02 -1.11312224e-02  1.46966632e-02\n -9.95430630e-03  1.71139892e-02 -2.74963747e-03  5.00850342e-02\n -4.21935780e-04  4.50983793e-02 -7.87406415e-03 -1.07329916e-02\n -1.32510848e-02 -1.54813975e-02  2.74343248e-02 -2.01084814e-03\n  1.04009658e-02  8.74902215e-03 -1.79225840e-02 -1.51767032e-02\n -7.99472164e-03  2.70181056e-02 -1.85326755e-03  2.31472645e-02\n -5.87810762e-03 -1.82054825e-02 -1.47399632e-02 -9.31331795e-03\n -6.47707982e-03 -1.02094859e-02 -1.99238677e-03 -6.79577235e-03\n -4.55139903e-03 -5.16729755e-03  1.32089965e-02  3.03320773e-03\n  6.02915371e-03  1.67796426e-02  4.79263179e-02  1.18438259e-01\n -3.84312379e-03 -1.79448575e-02  2.34223975e-04 -2.72942279e-02\n -7.65192090e-03 -1.73818190e-02  3.68986418e-03 -1.69613939e-02\n  4.05282248e-03 -2.17468967e-03 -1.22745882e-03  5.60747180e-03\n -5.77778742e-03 -1.92100415e-03 -2.39439290e-02 -9.25192516e-03\n  2.03177538e-02 -1.74451042e-02 -5.74261509e-03 -1.55136390e-02\n -2.29740310e-02 -1.85036194e-02  9.03297309e-03 -9.58338671e-04\n  2.28778040e-03  1.74048990e-02 -3.09807295e-03 -1.41907847e-02\n -1.10980207e-02 -4.28873673e-03 -1.42735858e-02 -1.07261436e-02\n  6.79549109e-03  1.05254324e-02 -8.26286152e-03 -1.16259733e-04\n -5.77471079e-03 -7.01528741e-03 -1.09376721e-02 -2.52304096e-02\n -1.60778146e-02 -3.25628370e-02 -4.39757016e-03 -1.50404517e-02\n  1.41684357e-02  2.10430613e-03 -4.02390352e-03 -8.54851305e-03\n  1.04183098e-02 -2.88566630e-02 -1.16745373e-02 -1.35866497e-02\n -2.73717986e-03 -3.95432720e-03  3.12655629e-03 -9.86162480e-03\n -5.42532746e-03 -1.65288076e-02 -9.16885678e-03 -2.36178958e-03\n  8.44173972e-03 -3.75277773e-02 -5.58282156e-03 -1.20817171e-02\n  1.23644369e-02 -2.02595778e-02  1.22572239e-02 -3.56633635e-03\n  3.21467174e-03  2.07786821e-03 -1.84619939e-03  2.98280548e-03\n -2.88315746e-03 -3.27647035e-03  1.04995735e-03 -1.49867535e-02\n -1.80263582e-04 -1.08881127e-02 -3.63583770e-03 -1.44072575e-02\n  2.35486007e-03  5.44905616e-03  4.30968903e-05 -5.58915967e-03\n  1.58288353e-03  1.12540834e-03  1.50501111e-03  4.85622513e-05\n  7.10887238e-02  2.45623905e-02  4.17112326e-03  9.68663301e-03\n -2.44593015e-03 -1.35366153e-02  2.65697092e-02  5.69682522e-03\n  8.83114524e-03  9.76116024e-03  3.58142029e-03  1.11642666e-02\n -3.62640107e-03 -9.25896317e-03 -2.68877810e-03 -1.65342744e-02\n -4.71546175e-03  5.17536933e-03 -6.08773436e-03  1.57244802e-02\n  1.35418335e-02  6.90288888e-03  2.63715629e-02  3.28032970e-02\n -5.52940764e-04 -2.82129776e-02  6.78708265e-03 -1.93769753e-03\n  2.58140452e-02  2.20634669e-04 -2.67390953e-03  1.35877468e-02\n -9.97097883e-03 -1.07128946e-02 -4.14283155e-03 -1.91842194e-03\n  2.51876175e-01 -5.45801334e-02 -1.16688444e-03 -7.58179929e-03\n -6.43453188e-03  3.76904407e-03 -5.95489750e-03 -1.11942217e-02\n -1.98358507e-03 -3.97853274e-03 -5.48746623e-03 -1.72425155e-02\n  6.91921450e-03  2.08226102e-03  4.07312112e-03  8.47579725e-03\n  4.02667880e-04 -2.88728089e-03  8.56931438e-04  3.78236244e-03\n  1.24191595e-02  1.58070102e-02  9.47103743e-03 -8.79033818e-04\n  2.02814839e-03 -1.47699127e-02  1.40712531e-02  2.17357706e-02\n -1.21472189e-02  6.67436840e-03  1.23163993e-02  1.16995014e-02\n -1.09447464e-02 -1.06686270e-02 -1.07520465e-02 -5.71267866e-03\n -3.97031847e-03  3.01123085e-03 -3.50862253e-03  1.08143138e-02\n  7.09780399e-03  3.86474691e-02 -8.64547770e-03 -1.57216936e-02\n -1.60572585e-03  1.51186169e-03 -2.14366300e-04  2.19937623e-03\n -1.35735171e-02  1.32408794e-02 -6.37209043e-03 -2.62701027e-02\n  2.04956438e-02 -1.11661234e-03 -6.14005560e-03 -5.91984310e-04\n -9.11653414e-03 -1.15093496e-02 -1.81612968e-02 -1.38785075e-02\n  3.56548443e-03  3.16919945e-02 -3.88763775e-03 -1.27605977e-03\n -7.26699363e-03 -1.12618888e-02  4.03732955e-02 -3.11432444e-02\n -8.70184787e-03 -1.92339141e-02 -3.09313228e-03 -6.55319076e-03\n  1.16343843e-02 -2.40492020e-02 -1.62653590e-03  1.55232521e-03\n -2.70218519e-03  3.35494988e-03  1.39744142e-02  1.74429864e-02\n  1.87636018e-02  1.99969552e-04  8.50964244e-03 -6.41091587e-03\n  4.34410805e-03 -1.18281031e-02 -1.46821821e-02 -7.44524598e-03\n  2.59720627e-02  1.88644063e-02  1.45326136e-02  2.93417834e-02\n  2.39911843e-02  2.94267386e-03  7.39233277e-04  4.35112230e-03\n  9.72558837e-03  4.48903674e-03  1.46556029e-03  5.04063303e-03\n -3.42193106e-03 -1.79710146e-02  1.16284229e-02 -4.36905102e-04\n -1.01666730e-02 -4.44995426e-03  2.59177536e-02 -2.31557637e-02\n  1.26353214e-02  2.62941252e-02  1.41547117e-02  2.49826927e-02\n -1.46170743e-02 -2.31623128e-02  5.82614541e-03  1.16367415e-02\n -1.13630202e-03 -2.28386149e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "'''\n",
    "    K-FOLD CROSS VALIDATION\n",
    "'''\n",
    "acc_total = 0\n",
    "\n",
    "for train_index, test_index in kf.split(df):\n",
    "    \n",
    "    X_train = df[train_index]\n",
    "    Y_train = target[train_index]\n",
    "    \n",
    "    X_test = df[test_index]\n",
    "    Y_test = target[test_index]\n",
    "    \n",
    "    #print(Y_train.shape)\n",
    "    #print(Y_test.shape)\n",
    "    \n",
    "    \n",
    "    model_svm = clf.fit(X_train,Y_train)\n",
    "    predictions = model_svm.predict(X_test)\n",
    "    \n",
    "    acc = 100*accuracy_score(Y_test,predictions)\n",
    "    \n",
    "    acc_total = acc_total + acc\n",
    "    \n",
    "print('accuracy = {}'.format(np.round(acc_total/10, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df, target, test_size = 0.3)\n",
    "model = clf.fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "acc = 100 * accuracy_score(Y_test, pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.scatter(df[:,1], target)\n",
    "#plt.scatter(Y_test,pred)\n",
    "#plt.plot(clf.predict(X_test), Y_test, label=\"Model\")\n",
    "#plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "#plt.scatter(df, target, edgecolor='b', s=20, label=\"Samples\")\n",
    "\n",
    "#plt.plot(X_test, model.predict(X_test), label=\"Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
